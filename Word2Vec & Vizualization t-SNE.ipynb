{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b2c8a69-4a39-43b9-96d3-92d4ac0c5149",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 1: Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ced3738-38d7-42fd-9b6c-a3e3240e2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Create the 15-tweet dataset\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    \"content\": [\n",
    "        \"AI is transforming the way we work and live.\",\n",
    "        \"ChatGPT is a powerful AI language model developed by OpenAI.\",\n",
    "        \"Artificial intelligence helps automate repetitive tasks.\",\n",
    "        \"Machine learning is a core component of AI systems.\",\n",
    "        \"Deep learning allows AI to recognize patterns in data.\",\n",
    "        \"OpenAI continuously improves ChatGPT with new updates.\",\n",
    "        \"AI can generate text, answer questions, and provide recommendations.\",\n",
    "        \"Natural language processing enables computers to understand human language.\",\n",
    "        \"ChatGPT can assist students, professionals, and researchers.\",\n",
    "        \"Businesses are using AI tools like ChatGPT for customer support.\",\n",
    "        \"AI research focuses on ethics, fairness, and safety.\",\n",
    "        \"Language models like ChatGPT learn from vast amounts of text data.\",\n",
    "        \"AI and machine learning are driving innovation across industries.\",\n",
    "        \"Developers can integrate AI models into applications via APIs.\",\n",
    "        \"Understanding AI requires knowledge of algorithms, data, and models.\"\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2489cad6-0ebd-4319-87e9-9fbb41b5c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Combine all tweets into a single text\n",
    "article_text = \" \".join(data[\"content\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f295d62a-1c6e-4fa1-b180-9b098ebaedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: Text Cleaning\n",
    "processed_text = article_text.lower()  # lowercase\n",
    "processed_text = re.sub('[^a-zA-Z]', ' ', processed_text)  # remove punctuation/numbers\n",
    "processed_text = re.sub(r'\\s+', ' ', processed_text)  # remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc823987-5f57-4c38-9fd6-7c6b85da22d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 5: Tokenization and Stopword Removal\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Tokenize sentences\n",
    "sentences = nltk.sent_tokenize(processed_text)\n",
    "\n",
    "# Tokenize words in each sentence\n",
    "words = [nltk.word_tokenize(sent) for sent in sentences]\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "clean_words = []\n",
    "for sent in words:\n",
    "    clean_sent = [w for w in sent if w not in stop_words]\n",
    "    clean_words.append(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc136feb-afdf-44f6-a4b1-1abb6343725d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 505)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Word2Vec Training\n",
    "\n",
    "model = Word2Vec(sentences=clean_words, vector_size=50, window=3, min_count=1, workers=2)\n",
    "model.train(clean_words, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4aaef01-7e5e-499a-9509-b78ba0741bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'ai':\n",
      " [-0.00103019  0.00043431  0.01005562  0.01828523 -0.01872372 -0.01440957\n",
      "  0.01312491  0.01824073 -0.01027128 -0.00757274  0.01466691 -0.00319589\n",
      " -0.00897254  0.01349374 -0.0097941  -0.0033181   0.00611263  0.00216332\n",
      " -0.0168591  -0.01914776  0.01475406  0.01034863  0.01377455  0.0015118\n",
      "  0.01304583 -0.00672515 -0.00210046  0.01169073 -0.0150704  -0.00775076\n",
      " -0.01489108 -0.0019779   0.01930053 -0.01491998 -0.00479967 -0.00373896\n",
      "  0.01637983 -0.0119998   0.00027307 -0.00962471 -0.01920346  0.00989878\n",
      " -0.01746352 -0.008828    0.00023493 -0.00066401 -0.01554193  0.0190484\n",
      "  0.01007564  0.01869814]\n",
      "Shape: (50,)\n"
     ]
    }
   ],
   "source": [
    "# 7: Demo Vector Output\n",
    "\n",
    "demo_word = \"ai\"\n",
    "if demo_word in model.wv:\n",
    "    demo_vector = model.wv[demo_word]\n",
    "    print(f\"Vector for '{demo_word}':\\n\", demo_vector)\n",
    "    print(\"Shape:\", demo_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a30084f-3faa-48bb-b149-ee6a9c262d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8: t-SNE Plot\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsne_plot(model):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    # Extract word vectors\n",
    "    for word in model.wv.index_to_key:\n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # Convert to NumPy array\n",
    "    tokens = np.array(tokens)\n",
    "\n",
    "    # t-SNE with small perplexity\n",
    "    tsne_model = TSNE(perplexity=5, n_components=2, init='pca', random_state=42, learning_rate='auto')\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = new_values[:, 0]\n",
    "    y = new_values[:, 1]\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.show()\n",
    "\n",
    "tsne_plot(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a5cb9-0186-4973-be84-49d1c6813bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
